---
title: "Untitled"
mainfont: DejaVu Sans
output:
  html_document: default
---

```{r}
library(maptools)
library(spdep)
library(leaflet)
library(RColorBrewer)
```


# Introducción

El tutorial fue preparado para los estudiantes graduados en la novena cumbre de Midwest sobre economía aplicada, regional y estudios urbanos (AERUS) en Abril 23-24 de 2016 para la Universidad de Illinois en Champaign urbana.

Estas notas ilustran el uso de r en análisis econometrico espacial. La teoría es basada en Anselin y Bera (1998) y Arbia (2014) y los aspectos prácticos son actualización de versión de Anselin (2003), con algunos adiciones en visualización espacial para datos r.

Comentarios y sugerencias son siempre bienvenidas y se pueden enviar a srmntbr2@illinois.edu1.


# ¿Qué es r y por qué usalo?

R es un software libre, código abierto, y lenguaje orientado a objetos. Libre y código abierto significa que cualquiera puede usarlo, redistribuir y cambiar el software de cualquier forma. Sin embargo, "R es un sofware libre con entorno computacional estadístico y gráficos. Esto compila y corre una amplia variedad de plataformas UNIX, windows y MacOS." (http://cran.r-project.org)


Existen muchos software externos que hacen el análisis de datos bonitos y parecen más fáciles que r, entonces porque debería invertir en apreder sobre R?. Existen en mi opinión al menos tres caracteristicas que R hacen que r valga la pena aprenderlo. Primero que todo, es gratis. Muchos software hoy en día son caros, pero r es gratis y siempre lo será. R también es un lenguaje, lo que significa que no solo puedes usar funciones que estén construidas en el software, sino que también puedes crear tus propias funciones  (para conocer el poder del lenguaje R puede echar un vistazo al Paquete de Regresión Cuantil del Profesor Koenker). La última razón es que R está extremadamente bien soportado. Si tiene una pregunta solamente puede buscarla en Google, publicarla en StackOverflow o usar R-blogger. Si aún no está convencido, simplemente puede escribir "por qué usar el lenguaje R" en Google y creo que los resultados hablarán por sí mismos.

Todas estas características más el hecho de que los investigadores en la frontera de la profesión usan R como parte de su investigación hace de R una gran herramienta para el análisis de datos espaciales.


```{r, message=FALSE}
library(pander)
library(knitr)
library(skimr)
library(leaflet)
```


# Introducción al análisis espacial en R

## Motivación para el uso de análisis espacial 

Probablemente el argumento más importante para adoptar un enfoque espacial es que el supuesto de independencia entre observaciones ya no es válido. Atributos de observación i puede influir en los atributos de observación j.

Para ilustrar un conjunto muy pequeño de lo que se puede lograr en R para el análisis espacial, nuestro ejemplo corriente examinará crímenes violentos y
ejecuciones hipotecarias en la ciudad de Chicago. Los datos de delitos, así como los archivos de formas de los tractos utilizados aquí provienen del Portal de Datos de Chicago, mientras que los datos de ejecuciones hipotecarias provienen del Departamento de Vivienda y Desarrollo Urbano de los EE. UU. (HUD), todos estos están disponibles al público.

Probably the most important argument for taking a spatial approach is that the independence assumption between observation is no longer valid. Attributes of observation i may influence the attributes of observation j.

To illustrate a very small set of what can be achieved in R for spatial analysis our running example will be examining violent crimes and foreclosures in the City of Chicago. The crime data as well as tracts shapefiles used here comes from Chicago Data Portal while foreclosures data come from the U.S. Department of Housing and Urban Development (HUD), all of these are public available.

## 3.2 R packages for spatial data analysis.

En R, la unidad fundamental del código que se puede compartir es el paquete. Un paquete agrupa código, datos, documentación y pruebas, y es fácil de compartir con otros. A abril de 2016, había más de 8,200 paquetes disponibles en la Red Integral de Archivos R, o CRAN, la cámara de compensación pública para paquetes R. Esta gran variedad de paquetes es una de las razones por las que R tiene tanto éxito: lo más probable es que alguien ya haya resuelto un problema en el que estás trabajando, y puedes beneficiarte de su trabajo descargando su paquete. (Wickham (2015))

Hoy nos centraremos en tres paquetes maptools (R. Bivand y Lewin Koh (2016)), spdep (R. Bivand y Piras (2015), R. Bivand, Hauke y Kossowski (2013)) y folleto (Cheng y Xie (2015)) y use un cuarto, el paquete RColorBrewer (Neuwirth (2014)) para hacer nuestras parcelas más atractivas. Para instalar los paquetes, simplemente tenemos que escribir

In R, the fundamental unit of shareable code is the package. A package bundles together code, data, documentation, and tests, and is easy to share with others. As of April 2016, there were over 8,200 packages available on the Comprehensive R Archive Network, or CRAN, the public clearing house for R packages. This huge variety of packages is one of the reasons that R is so successful: the chances are that someone has already solved a problem that you’re working on, and you can benefit from their work by downloading their package. (Wickham (2015))

Today we’ll focus on three packages maptools (R. Bivand and Lewin-Koh (2016)), spdep (R. Bivand and Piras (2015), R. Bivand, Hauke, and Kossowski (2013)) and leaflet (Cheng and Xie (2015)) and use a fourth one, the RColorBrewer package (Neuwirth (2014)) to make our plots more attractive. To install the packages, we simple have to type


## 3.3 Reading and Mapping spatial data in R

Los datos espaciales vienen en muchas "formas" y "tamaños", los tipos más comunes de datos espaciales son:

Los puntos son la forma más básica de datos espaciales. Denota una ubicación de un solo punto, como ciudades, una lectura de GPS o cualquier otro objeto discreto definido en el espacio.

Las líneas son un conjunto de puntos ordenados, conectados por segmentos de línea recta. Los polígonos denotan un área, y pueden pensarse como una secuencia de puntos conectados, donde el primer punto es el mismo que la última Cuadrícula (Ráster) es una colección de puntos o rectangular células, organizadas en una red regular

Para más detalles, ver R. S. Bivand, Pebesma y Gomez-Rubio (2008). Hoy nos centraremos en los polígonos. Los datos espaciales generalmente vienen en forma de archivo. Este tipo de archivos almacena información de geometría y atributos no topológicos para las características espaciales en un conjunto de datos.

Además, no requieren mucho espacio en disco y son fáciles de leer y escribir. (ESRI (1998))

Primero tenemos que descargar y guardar los archivos en nuestra computadora desde nuestro servidor en http://www.econ.uiuc.edu/~lab/workshop/foreclosures/. Guardé el mío en mi escritorio. Hemos descargado 3 archivos:

+ Archivo principal: foreclosures.shp
+ Archivo de índice: foreclosures.shx
+ Tabla + dBASE: ejecuciones hipotecarias.dbf

El archivo principal describe una forma con una lista de sus vértices. En el archivo de índice, cada registro contiene el desplazamiento del registro del archivo principal correspondiente desde el comienzo del archivo principal. La tabla dBASE contiene atributos de características con un registro por característica. (ESRI (1998))

Para leer datos de un archivo de forma de polígono en R, utilizamos la función readShapePoly que creará un objeto SpatialPolygonsDataFrame. Para obtener más información sobre la función, el comando? ReadShapePoly le dará acceso al archivo de ayuda.

Pero antes de leer en el shapefile primero configuramos nuestro directorio de trabajo. R siempre apunta a un directorio en su computadora, para encontrar cuál usa getwd () (obtener el directorio de trabajo). Para especificar un directorio de trabajo:

Spatial data comes in many “shapes” and “sizes”, the most common types of spatial data are:

Points are the most basic form of spatial data. Denotes a single point location, such as cities, a GPS reading or any other discrete object defined in space.
Lines are a set of ordered points, connected by straight line segments Polygons denote an area, and can be thought as a sequence of connected points, where the first point is the same as the last Grid (Raster) are a collection of points or rectangular cells, organized in a regular lattice

For more details, see R. S. Bivand, Pebesma, and Gomez-Rubio (2008). Today we’ll focus on Polygons. Spatial data usually comes in shapefile. This type of files stores non topological geometry and attribute information for the spatial features in a data set. 

Moreover, they don’t require a lot of disk space and are easy to read and write. (ESRI (1998))

First we have to download and save the files in our computer from our server at http://www.econ.uiuc.edu/~lab/workshop/foreclosures/. I saved mine in my desktop. We’ve downloaded 3 files:

+ Main file: foreclosures.shp
+ Index file: foreclosures.shx
+ dBASE table: foreclosures.dbf

The main file describes a shape with a list of its vertices. In the index file, each record contains the offset of the corresponding main file record from the beginning of the main file. The dBASE table contains feature attributes with one record per feature. (ESRI (1998))

To read data from a polygon shapefile into R we use the function readShapePoly that will create a SpatialPolygonsDataFrame object. To learn more about the function, the command ?readShapePoly will give you access to the help file.

But before reading in the shapefile we first set our working directory. R is always pointing to a directory on your computer, to find which one use getwd() (get working directory). To specify a working directory:

```{r}
setwd('~/Desktop/foreclosures')
```

En Windows puede que tenga que usar \. La carpeta de ejecuciones hipotecarias contiene los archivos de forma que descargué antes. Ahora estamos listos para leer en nuestro shapefile.

On windows you may have to use \. The foreclosures folder contain the shapefiles that I downloaded before. Now we are ready to read in our shapefile.

```{r}
chi.poly <- readShapePoly('foreclosures.shp')
```

el archivo de forma ahora se lee y se almacena en un objeto llamado chi.poly. Para verificar que es un SpatialPolygonsDataFrame, podemos usar la clase de función

the shapefile is now read and stored in an object called chi.poly. To check that it is a SpatialPolygonsDataFrame we can use the function class

```{r}
class
```


Un objeto SpatialPolygonsDataFrame reúne las representaciones espaciales de los polígonos con datos. Las etiquetas de identificación de los polígonos en la ranura coinciden con los nombres de fila del marco de datos para asegurarse de que las filas de datos correctas estén asociadas con el objeto espacial correcto. (R. S. Bivand, Pebesma y Gómez-Rubio (2008))

Este objeto tiene cuatro "partes" o ranuras: la primera es la ranura de datos que contiene las variables que se utilizarán para nuestro análisis; el segundo es la ranura del polígono y contiene la información de "forma". El tercer espacio, bbox, es el cuadro delimitador dibujado alrededor de los límites y el cuarto espacio es la cadena proj4 que contiene las proyecciones. Para acceder a la ranura de datos podemos usar la función de ranura o el símbolo @. Para una apariencia compacta de la ranura de datos, podemos usar la función str:

A SpatialPolygonsDataFrame objects brings together the spatial representations of the polygons with data. The identifying tags of the polygons in the slot are matched with the row names of the data frame to make sure that the correct data rows are associated with the correct spatial object. (R. S. Bivand, Pebesma, and Gomez-Rubio (2008))

This object has four “parts” or slots: the first one is the data slot that contains the variables that will be used for our analysis; the second one is the polygon slot and contains the “shape” information. The third slot, bbox, is the bounding box drawn around the boundaries and the fourth slot is the proj4string which contains the projections. To access the data slot we can use the slot function or the @ symbol. For a compact look of the data slot we can use the str function:


```{r}
str(slot(chi.poly,"data"))
```

La primera parte es la parte data.frame que contiene los datos para nuestro análisis. Podemos ver las variables contenidas en la porción de datos del archivo, incluyendo:

+ est_fcs: el recuento estimado de ejecuciones hipotecarias comienza desde enero de 2007 hasta junio de 2008
+ est_mtgs: número estimado de hipotecas activas desde enero de 2007 hasta junio de 2008
+ est_fcs_rt: número de ejecuciones hipotecarias iniciadas dividido por número de hipotecas multiplicado por 100
+ bls_unemp: lugar de junio de 2008 o tasa de desempleo del condado
+ totpop: población total del Censo 2000
+ violento: número de delitos violentos denunciados entre enero de 2007 y diciembre de 2008
+ propiedad: número de delitos contra la propiedad denunciados entre enero de 2007 y diciembre de 2008

También podemos obtener estadísticas resumidas de las variables de interés utilizando el resumen de funciones. Por ejemplo,


The first part is the data.frame part that contains the data for our analysis. We can see the variables contained in the data portion of the file including:

+ est_fcs: estimated count of foreclosure starts from Jan. 2007 through June 2008
+ est_mtgs: estimated number of active mortgages from Jan. 2007 through June 2008
+ est_fcs_rt: number of foreclosure starts divided by number of mortgages times 100
+ bls_unemp: June 2008 place or county unemployment rate
+ totpop: total population from 2000 Census
+ violent: number of violent crimes reported between Jan. 2007 through December 2008
+ property: number of property crimes reported between Jan. 2007 through December 2008

We can also get summary statistics of the variables of interest using the function summary. For example,

```{r}
summary(chi.poly@data$violent)
```


Aquí accedimos a la porción de datos del archivo de forma con el signo @ y luego a la variable con el signo $. Para ver las otras ranuras, podemos proceder de la misma manera.

Una buena característica de la clase de objetos espaciales es que podemos usar las características de trazado tradicionales de R. El siguiente comando nos proporciona un diagrama de las secciones censales de Chicago:


Here we accessed the data portion of the shapefile with the @ sign and then the variable with the $ sign. To see the other slots, we can proceed in the same fashion.

A nice feature of the class of spatial objects is that we can use the traditional plotting features of R. The following command give’s us a plot of Chicago’s Census Tracts:

```{r}
plot(chi.poly)
```

pero podemos ir un paso más allá y hacer mejores parcelas usando el paquete de folleto. Esto genera un mapa interactivo que se puede representar en páginas HTML.

but we can go a step further and make nicer plots using the leaflet package. This generates an interactive map that can be rendered on HTML pages.


```{r}
leaflet(chi.poly) %>%
  addPolygons(stroke = FALSE, fillOpacity = 0.5, smoothFactor = 0.5) %>%
  addTiles() #adds a map tile, the default is OpenStreetMap
```

Podemos agredar color usando el paquete RColorBrewer

```{r}
qpal<-colorQuantile("OrRd", chi.poly@data$violent, n=9) 

leaflet(chi.poly) %>%
  addPolygons(stroke = FALSE, fillOpacity = .8, smoothFactor = 0.2, color = ~qpal(violent)
  ) %>%
  addTiles()
```

función colorQuantile del paquete de folleto mapea los valores de los datos a colores siguiendo una paleta. En este caso, he especificado una paleta de Naranjas y Rojos, para más paletas puede acceder al archivo de ayuda de RColorBrewer:? RColorBrewer.

The colorQuantile function of the leaflet package maps values of the data to colors following a palette. In this case I’ve specified a palette of Oranges and Reds, for more palettes you can access the help file for RColorBrewer: ?RColorBrewer.

# 4 Econometría espacial en R

When dealing with space one must bear in mind Tobler’s first law of geography “Everything is related to everything else, but close things are more related than things that are far apart”(Tobler (1979)). In this section we’ll focus on the specification of spatial dependence, on specification tests to detect spatial dependence in regressions models and on basic regression models that incorporate spatial dependence. We’ll illustrate this using the data in the shapefile loaded in the previous section.

## Mínimos cuadrado ordinales (OLS)

El enfoque tradicional durante muchos años ha sido ignorar la dependencia espacial de los datos y simplemente ejecutar una regresión OLS.

 $y=Xβ+ϵ$

En R esto se logra con la función $lm$, por ejemplo:

```{r}
chi.ols<-lm(violent~est_fcs_rt+bls_unemp, data=chi.poly@data)
```

He especificado el "modelo" como $ violento ~ est_fcs_rt + bls_unemp $ donde violento es la variable dependiente y, est_fcs_rt y bls_unemp son la variable explicativa. También he especificado el conjunto de datos que son los datos de la ranura de nuestro archivo de forma. Tenga en cuenta que para acceder a este espacio utilizo el símbolo @. Esta línea no devuelve nada porque hemos creado un objeto lm que llamé chi.ols. Para ver los resultados, utilizamos la función de resumen

I’ve specified the “model” as $violent~est_fcs_rt+bls_unemp$ where violent is the dependent variable and, est_fcs_rt and bls_unemp are the explanatory variable. I’ve also specified the data set which is the slot data of our shapefile. Note that to access this slot I use the @ symbol. This line does not return anything because we have created an lm object that I called chi.ols. To see the results, we use the summary function

```{r}
summary(chi.ols)
```

El problema de ignorar la estructura espacial de los datos implica que las estimaciones de OLS en el modelo no espacial pueden ser sesgadas, inconsistentes o ineficientes, dependiendo de cuál sea la verdadera dependencia subyacente (para más información, ver Anselin y Bera (1998)).

The problem with ignoring the spatial structure of the data implies that the OLS estimates in the non spatial model may be biased, inconsistent or inefficient, depending on what is the true underlying dependence (for more see Anselin and Bera (1998)).

## 4.2 Modeling Spatial Dependence

We now take a closer look at spatial dependence, or to be more precise on it’s weaker expression spatial autocorrelation. Spatial autocorrelation measures the degree to which a phenomenon of interest is correlated to itself in space (Cliff and Ord (1973)). In other words, similar values appear close to each other, or cluster, in space (positive spatial autocorrelation) or neighboring values are dissimilar (negative spatial autocorrelation). Null spatial autocorrelation indicates that the spatial pattern is random. Following Anselin and Bera (1998) we can express the existence of spatial autocorrelation with the following moment condition:

$Cov(yi,yj)≠0fori≠j$

were $yi$ and $yj$ are observations on a random variable at locations i and j. The problem here is that we need to estimate $N$ by $N$ covariance terms directly for $N$ observations. To overcome this problem we impose restrictions on the nature of the interactions. One type of restriction is to define for each data point a relevant “neighborhood set”. In spatial econometrics this is operationalized via the spatial weights matrix. The matrix usually denoted by $W$ is a $N$ by $N$ positive and symmetric matrix which denotes fore each observation (row) those locations (columns) that belong to its neighborhood set as nonzero elements (Anselin and Bera (1998), Arbia (2014)), the typical element is then:

$[wij]={10ifj∈N(i)o.w$

$N(i)$  being the set of neighbors of location j. By convention, the diagonal elements are set to zero, i.e. $wii=0$. To help with the interpretation the matrix is often row standardized such that the elements of a given row add to one.

The specification of the neighboring set is quite arbitrary and there’s a wide range of suggestions in the literature. One popular way is to use one of the two following criteria:

+ Rook criterion: two units are close to one another if they share a side
+ Queen criterion: two units are close if they share a side or an edge.


Another used approach is to denote two observations as neighbors if they are within a certain distance, i.e., j∈N(j) if dij<dmax where d is the distance between location i and j.

Here we’ll focus on using the queen criterion and we encourage the reader to experiment with the rook criterion. In R to obtain the weights matrix we make use of two functions. In the first step we use poly2nb which builds a neighbors list, if the option queen=TRUE is specified it will be build using the queen criterion. If FALSE is specified, then the rook criteria will be used. The next step is to supplement the neighbors list with the spatial weights. The option W row standardizes the matrix.


```{r}
list.queen<-poly2nb(chi.poly, queen=TRUE)
W<-nb2listw(list.queen, style="W", zero.policy=TRUE)
W
```


We can plot the link distribution with the usual plot function

```{r}
plot(W,coordinates(chi.poly))
```


To obtain the weight matrix based on distances we use two functions: coordinates that will retrieve the centroid coordinates of the census tracts polygons and dnearneigh that will identify neighbors between two distances in kilometers measured using Euclidean distance. For example, to find neighbors within 1 kilometer we do:

```{r}
coords<-coordinates(chi.poly)
W_dist<-dnearneigh(coords,0,1,longlat = FALSE)
```

I encourage you to compare the link distributions for these three ways of defining neighbors.

4.2.1 Spatial Autoregressive (SAR) Models
Spatial lag dependence in a regression setting can be modeled similar to an autoregressive process in time series. Formally,

y=ρWy+Xβ+ϵ

The presence of the term Wy induces a nonzero correlation with the error term, similar to the presence of an endogenous variable, but different from the time series context. Contrarious to time series, [Wy]i is always correlated with ϵi irrespective of the structure of the errors. This implies that OLS estimates in the non spatial model will be biased and inconsistent. (Anselin and Bera (1998))

4.2.2 Spatial Error Models (SEM)
Another way to model spatial autocorrelation in a regression model is to specify the autoregressive process in the error term:

y=Xβ+ϵ

with

ϵ=λWϵ+u

If this is the “true” form of spatial dependence OLS estimates will be unbiased but inefficient.

4.3 Testing for spatial autocorrelation
There are multiple tests for testing the presence of spatial autocorrelation. In this note we’ll focus on a restricted set: Moran’s I test and Lagrange Multiplier tests.

4.3.1 Moran’s I Test
Moran’s I test was originally developed as a two-dimensional analog of Durbin-Watson’s test

$I=(e′Wee′e)$

where e=y−Xβ is a vector of OLS residuals β=(X′X)−1X′y, W is the row standardized spatial weights matrix.(For more detail see Anselin and Bera (1998))

To perform a Moran test on our data we need two inputs, an lm regression object (estimated in the OLS section) and the spatial weight matrix

```{r}
moran.lm<-lm.morantest(chi.ols, W, alternative="two.sided")
print(moran.lm)
```

The computation of the statistic is relative to a given choice of the spatial weights W. Different specifications of the weights matrix will give different results. I encourage the reader to try this with the rook contiguity criterion.

##  4.3.2 Lagrange Multiplier Test

A nice feature of Moran’s I test is that i has high power against a wide range of alternatives (Anselin and Bera (1998)). However, it does not guide us in the selection of alternative models. On the other hand, Lagrange Multiplier test specify the alternative hypothesis which will help us with the task. The LM tests for spatial dependence are included in the lm.LMtests function and include as alternatives the presence of a spatial lag and the presence of a spatial lag in the error term. Both tests, as well as their robust forms are included in the lm.LMtests function. To call them we use the option test="all". Again, a regression object and a spatial listw object must be passed as arguments:

```{r}
LM<-lm.LMtests(chi.ols, W, test="all")
print(LM)
```

Since LMerr and LMlag are both statistically significant different from zero, we need to look at their robust counterparts. These robust counterparts are actually robust to the presence of the other “type” of autocorrelation. The robust version of the tests suggest that the lag model is the more likely alternative.

4.4 Running Spatial Regressions
4.4.1 SAR Models
The estimation of the SAR model can be approached in tw

```{r}
sar.chi<-lagsarlm(violent~est_fcs_rt+bls_unemp, data=chi.poly@data, W)
summary(sar.chi)
```

Another way is to use 2SLS using the function stsls. I leave this to the reader so he/she can compare the results to the MLE approach. The function is:

```{r}
sar2sls.chi<-stsls(violent~est_fcs_rt+bls_unemp, data=chi.poly@data, W)
summary(sar2sls.chi)
```

We then can compare the residuals of the OLS regression to the residuals of the spatial autoregressive model. To access the residuals for the OLS model and the SAR model we simply do

```{r}
chi.poly@data$chi.ols.res<-resid(chi.ols) #residuals ols

chi.poly@data$chi.sar.res<-resid(sar.chi) #residual sar
```


In this step I’ve create a new variable in the data portion of the shapefile that will help with the plotting of the residuals. To plot the residuals, I use the spplot function in the spdep package. The arguments are the shapefile, the variable that we want to plot, the number of breaks and the colors we are going to use. To specify the colors, we use the Red and Blues (RdBu) palette from the RColorBrewer package.

```{r}
spplot(chi.poly,"chi.ols.res", at=seq(min(chi.poly@data$chi.ols.res,na.rm=TRUE),max(chi.poly@data$chi.ols.res,na.rm=TRUE),length=12),col.regions=rev(brewer.pal(11,"RdBu")))
```

```{r}
spplot(chi.poly,"chi.sar.res",at=seq(min(chi.poly@data$chi.sar.res,na.rm=TRUE),max(chi.poly@data$chi.sar,na.rm=TRUE), length=12), col.regions=rev(brewer.pal(11,"RdBu")))
```

## 4.4.1.1 Marginal Effects

Note that the presence of the spatial weights matrix makes marginal effects richer and slightly more complicated than in the “traditional” OLS model. We’ll have three impact measures suggested by Pace and LeSage (2009) and is done in R with the function impacts

```{r}
impacts(sar.chi, listw=W)
```

The direct impact refers to average total impact of a change of an independent variable on the dependent fore each observation, i.e., n−1∑ni=1∂E(yi)∂Xi, the indirect impact which is the sum of the impact produced on one single observation by all other observations and the impact of one observation on all the other. The total is the summation of the two

## 4.4.2 SEM Models

On the other hand, if we want to estimate the Spatial Error Model we have two approaches again. First, we can use Maximum Likelihood as before, with the function errorsarlm

```{r}
errorsalm.chi<-errorsarlm(violent~est_fcs_rt+bls_unemp, data=chi.poly@data, W)
summary(errorsalm.chi)
```

The same plot for the SEM residuals can be done as before and is left for the reader. A second approach is use Feasible Generalized Least Squares (GLS) with the function GMerrorsar. The function is:

```{r}
fgls.chi<-GMerrorsar(violent~est_fcs_rt+bls_unemp, data=chi.poly@data, W)
summary(fgls.chi)
```

Finally, if we look at the likelihood for the SAR model and SEM model we see that we achieve a lower value for the SAR model that was the model favored by the LMtests. The residuals plot presented above still show some presence of spatial autocorrelation. It’s very likely that the a more complete model is specified. The literature has expanded to more complex models. The reader is encouraged to read Anselin and Bera (1998), Arbia (2014) and Pace and LeSage (2009) for more detailed and complete introductions on Spatial Econometrics.

References

Anselin, Luc. 2003. “An Introduction to Spatial Regression Analysis in R.” Available at: Https://geodacenter.asu.edu/drupal_files/spdepintro.pdf.

Anselin, Luc, and Anil K Bera. 1998. “Spatial Dependence in Linear Regression Models with an Introduction to Spatial Econometrics.” Statistics Textbooks and Monographs 155. MARCEL DEKKER AG: 237–90.

Arbia, Giuseppe. 2014. A Primer for Spatial Econometrics: With Applications in R. Palgrave Macmillan.

Bivand, Roger S, Edzer J Pebesma, and Virgilio Gomez-Rubio. 2008. Applied Spatial Data Analysis with R. Springer. Springer.

Bivand, Roger, and Nicholas Lewin-Koh. 2016. Maptools: Tools for Reading and Handling Spatial Objects. https://CRAN.R-project.org/package=maptools.

Bivand, Roger, and Gianfranco Piras. 2015. “Comparing Implementations of Estimation Methods for Spatial Econometrics.” Journal of Statistical Software 63 (18): 1–36. http://www.jstatsoft.org/v63/i18/.

Bivand, Roger, Jan Hauke, and Tomasz Kossowski. 2013. “Computing the Jacobian in Gaussian Spatial Autoregressive Models: An Illustrated Comparison of Available Methods.” Geographical Analysis 45 (2): 150–79. http://www.jstatsoft.org/v63/i18/.

Cheng, Joe, and Yihui Xie. 2015. Leaflet: Create Interactive Web Maps with the JavaScript ’Leaflet’ Library. http://rstudio.github.io/leaflet/.

Cliff, Andrew David, and J Keith Ord. 1973. Spatial Autocorrelation. Vol. 5. Pion London.

ESRI, Environmental Systems Research Institute. 1998. “ESRI Shapefile Technical Description.” Available at: Https://www.esri.com/library/whitepapers/pdfs/shapefile.pdf.

Neuwirth, Erich. 2014. RColorBrewer: ColorBrewer Palettes. https://CRAN.R-project.org/package=RColorBrewer.

Pace, R Kelley, and JP LeSage. 2009. “Introduction to Spatial Econometrics.” Boca Raton, FL: Chapman &Hall/CRC.

Tobler, WR. 1979. “Cellular Geography.” In Philosophy in Geography, 379–86. Springer.

Wickham, Hadley. 2015. R Packages. “O’Reilly Media, Inc.”